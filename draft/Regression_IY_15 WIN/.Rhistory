data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
######fisrt step######################### winsorizing
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA1","ABSDA","ABSDA","RM","RM1","RM2")
X_vars <- c("ABSDA1","ABSDA","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, "  + INST+ MS　+ LEV + OCF + MTB + ADJROA + LGTA + Age + RD + ESG + ADV + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + INST+ MS + LEV + OCF + MTB + ADJROA  + LGTA + Age  + RD + ADV + ESG  + Big4 + Year")), data = data,link="logit",method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + INST + MS + LEV + OCF + MTB + ADJROA + LGTA + Age  + RD  + ADV + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Output matched_data to CSV
csv_filename <- paste0("matched_data_", Y_var, "_", X_var, ".csv")
#write.csv(matched_data, file = csv_filename, row.names = FALSE)
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
}
}
}
# Output all models in a single table using stargazer
stargazer::stargazer(models, type = "html", out = "PSM.html",
se = se_list, title = "PSM-Regression Results with Clustered Standard Errors")
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("Total.csv")
# 移除含有缺失值的觀測值
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
########### winsorizing 1%
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$ADJROA_sq<-data$ADJROA*data$ADJROA
#Now, perform the Huber regression or any regression analysis using winsorized variables+ Year + Industry
#AM
#sink("AM_N.txt")
# Define the different values for Y and X
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
Y_vars <- c("ABSDA","ABSDA1") # Updated Y_vars to distinguish between positive and negative DA2
X_vars <- c("RM")
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
# Define the model formula
formula <- as.formula(paste0(gsub("_pos|_neg", "", Y_var), " ~ RPA_Ctd  * ", X_var, " + INST + MS + LEV + OCF + MTB + ADJROA + LGTA + Age + RD + ADV + ESG + Big4 + Year"))
# Filter data based on the condition (if applicable)
if (Y_var == "DA1_pos") {
temp_data <- data[data$DA1 > 0, ]
} else if (Y_var == "DA1_neg") {
temp_data <- data[data$DA1 < 0, ]
} else {
temp_data <- data
}
# Fit the model with the filtered data
model <- lm(formula, data = temp_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Store the model and its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
}
}
# Output all models in a single table
stargazer(models, type = "html",
se = se_list,
title = "AM-Regression Results with Clustered Standard Errors", out = "AM.html")
# RM
#sink("RM.txt")
# Define the different values for Y and X
# Assuming 'data' is your dataframe and 'Key' is your clustering variable
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
X_vars <- c("ABSDA","ABSDA1")
Y_vars <- c("ABCFO","ABPROD","ABEXP","RM","RM1","RM2")
for (Y_var in Y_vars) {
for (X_var in X_vars) {
# Define the model formula+ ", X_var, "
formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd  * ", X_var, " + INST + MS + LEV + OCF + MTB + ADJROA + LGTA + Age + RD + ADV + ESG + Big4 + Year"))
# Fit the model
model <- lm(formula, data = data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Store the model and its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
}
}
# Assuming you want to output all models in a single table
stargazer(models, type = "html",
se = se_list,
title = "RM-Regression Results with Clustered Standard Errors", out = "RM.html")
library(sandwich)
library(lmtest)
library(MASS)
library(Matching)
library(rgenoud)
library(MatchIt)
library(dplyr)
library(knitr)
library(kableExtra)
# read CSV
data <- read.csv("Total.csv", na.strings = "#N/A")
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
######fisrt step######################### winsorizing
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA1","ABSDA","ABSDA","RM","RM1","RM2")
X_vars <- c("ABSDA1","ABSDA","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, "  + INST+ MS　+ LEV + OCF + MTB + ADJROA + LGTA + Age + RD + ESG + ADV + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + INST+ MS + LEV + OCF + MTB + ADJROA  + LGTA + Age  + RD + ADV + ESG  + Big4 + Year")), data = data,link="logit",method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + INST + MS + LEV + OCF + MTB + ADJROA + LGTA + Age  + RD  + ADV + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Output matched_data to CSV
csv_filename <- paste0("matched_data_", Y_var, "_", X_var, ".csv")
write.csv(matched_data, file = csv_filename, row.names = FALSE)
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
}
}
}
library(sandwich)
library(lmtest)
library(MASS)
library(Matching)
library(rgenoud)
library(MatchIt)
library(dplyr)
library(knitr)
library(kableExtra)
# read CSV
data <- read.csv("Total.csv", na.strings = "#N/A")
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
######fisrt step######################### winsorizing
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA1","ABSDA","ABSDA","RM","RM1","RM2")
X_vars <- c("ABSDA1","ABSDA","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, "  + INST+ MS　+ LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age + RD + ESG + ADV + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + INST+ MS + LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age  + RD + ADV + ESG  + Big4 + Year")), data = data,link="logit",method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + INST + MS + LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age  + RD  + ADV + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Output matched_data to CSV
csv_filename <- paste0("matched_data_", Y_var, "_", X_var, ".csv")
#write.csv(matched_data, file = csv_filename, row.names = FALSE)
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
}
}
}
# Output all models in a single table using stargazer
stargazer::stargazer(models, type = "html", out = "PSM_.html",
se = se_list, title = "PSM-Regression Results with Clustered Standard Errors")
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
library(corrtable)
library(coin)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("matched_data_ABSDA1_RM.csv")
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
library(corrtable)
library(coin)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("matched_data_ABSDA1_RM.csv")
# 移除含有缺失值的觀測值
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
########### winsorizing 1%
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
# Des1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")]
stargazer(mydata, type = "html", title="Descriptive statistics", digits=5, out="des1_AM.html",summary.stat = c("mean","median","sd","min","max","p25","p75","n"))
#Des2
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_AM.html")
#Des2.1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM")]
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_1_AM.html")
#Des3
mydata<-data[,c("RPA_Ctd","ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")]
# Initialize a list to store results
variables<-c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")
results <- list()
# Loop through each variable to calculate stats and perform tests
for (var in variables) {
# Separate the groups
group_rpa <- filter(mydata, RPA_Ctd == 1) %>% pull(!!sym(var))
group_non_rpa <- filter(mydata, RPA_Ctd == 0) %>% pull(!!sym(var))
# Calculate statistics
mean_rpa <- mean(group_rpa, na.rm = TRUE)
median_rpa <- median(group_rpa, na.rm = TRUE)
sd_rpa <- sd(group_rpa, na.rm = TRUE)
mean_non_rpa <- mean(group_non_rpa, na.rm = TRUE)
median_non_rpa <- median(group_non_rpa, na.rm = TRUE)
sd_non_rpa <- sd(group_non_rpa, na.rm = TRUE)
# Wilcoxon test
test_result <- wilcox_test(reformulate('RPA_Ctd', response = var), data = mydata)
p_value <- pvalue(test_result)
# Store results
results[[var]] <- c(mean_rpa, median_rpa, sd_rpa, mean_non_rpa, median_non_rpa, sd_non_rpa, p_value)
}
# Convert results to a dataframe for easier manipulation and display
results_df <- do.call(rbind, results)
colnames(results_df) <- c("Mean RPA", "Median RPA", "SD RPA", "Mean Non-RPA", "Median Non-RPA", "SD Non-RPA", "P-Value")
rownames(results_df) <- variables
# Convert the results dataframe to a matrix for stargazer
results_matrix <- as.matrix(results_df)
# Use stargazer to create a table
stargazer(results_matrix, type = "html",out="des3_AM.html",digits = 4, title = "Comparative Statistics: RPA vs. Non-RPA Firms", summary = FALSE)
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
library(corrtable)
library(coin)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("matched_data_RM_ABSDA1.csv")
# 移除含有缺失值的觀測值
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
########### winsorizing 1%
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
# Des1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")]
stargazer(mydata, type = "html", title="Descriptive statistics", digits=5, out="des1_RM.html",summary.stat = c("mean","median","sd","min","max","p25","p75","n"))
#Des2
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_RM.html")
#Des2.1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM")]
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_1_RM.html")
#Des3
mydata<-data[,c("RPA_Ctd","ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")]
# Initialize a list to store results
variables<-c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")
results <- list()
# Loop through each variable to calculate stats and perform tests
for (var in variables) {
# Separate the groups
group_rpa <- filter(mydata, RPA_Ctd == 1) %>% pull(!!sym(var))
group_non_rpa <- filter(mydata, RPA_Ctd == 0) %>% pull(!!sym(var))
# Calculate statistics
mean_rpa <- mean(group_rpa, na.rm = TRUE)
median_rpa <- median(group_rpa, na.rm = TRUE)
sd_rpa <- sd(group_rpa, na.rm = TRUE)
mean_non_rpa <- mean(group_non_rpa, na.rm = TRUE)
median_non_rpa <- median(group_non_rpa, na.rm = TRUE)
sd_non_rpa <- sd(group_non_rpa, na.rm = TRUE)
# Wilcoxon test
test_result <- wilcox_test(reformulate('RPA_Ctd', response = var), data = mydata)
p_value <- pvalue(test_result)
# Store results
results[[var]] <- c(mean_rpa, median_rpa, sd_rpa, mean_non_rpa, median_non_rpa, sd_non_rpa, p_value)
}
# Convert results to a dataframe for easier manipulation and display
results_df <- do.call(rbind, results)
colnames(results_df) <- c("Mean RPA", "Median RPA", "SD RPA", "Mean Non-RPA", "Median Non-RPA", "SD Non-RPA", "P-Value")
rownames(results_df) <- variables
# Convert the results dataframe to a matrix for stargazer
results_matrix <- as.matrix(results_df)
# Use stargazer to create a table
stargazer(results_matrix, type = "html",out="des3_RM.html",digits = 4, title = "Comparative Statistics: RPA vs. Non-RPA Firms", summary = FALSE)
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
library(corrtable)
library(coin)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("Total.csv")
# 移除含有缺失值的觀測值
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
########### winsorizing 1%
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
# Des1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")]
stargazer(mydata, type = "html", title="Descriptive statistics", digits=5, out="des1.html",summary.stat = c("mean","median","sd","min","max","p25","p75","n"))
#Des2
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2.html")
#Des2.1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM")]
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_1.html")
#Des3
mydata<-data[,c("RPA_Ctd","ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")]
# Initialize a list to store results
variables<-c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","INST","MS","Age","RD","ADV","ESG","MTB","OCF","LEV","LGTA")
results <- list()
# Loop through each variable to calculate stats and perform tests
for (var in variables) {
# Separate the groups
group_rpa <- filter(mydata, RPA_Ctd == 1) %>% pull(!!sym(var))
group_non_rpa <- filter(mydata, RPA_Ctd == 0) %>% pull(!!sym(var))
# Calculate statistics
mean_rpa <- mean(group_rpa, na.rm = TRUE)
median_rpa <- median(group_rpa, na.rm = TRUE)
sd_rpa <- sd(group_rpa, na.rm = TRUE)
mean_non_rpa <- mean(group_non_rpa, na.rm = TRUE)
median_non_rpa <- median(group_non_rpa, na.rm = TRUE)
sd_non_rpa <- sd(group_non_rpa, na.rm = TRUE)
# Wilcoxon test
test_result <- wilcox_test(reformulate('RPA_Ctd', response = var), data = mydata)
p_value <- pvalue(test_result)
# Store results
results[[var]] <- c(mean_rpa, median_rpa, sd_rpa, mean_non_rpa, median_non_rpa, sd_non_rpa, p_value)
}
# Convert results to a dataframe for easier manipulation and display
results_df <- do.call(rbind, results)
colnames(results_df) <- c("Mean RPA", "Median RPA", "SD RPA", "Mean Non-RPA", "Median Non-RPA", "SD Non-RPA", "P-Value")
rownames(results_df) <- variables
# Convert the results dataframe to a matrix for stargazer
results_matrix <- as.matrix(results_df)
# Use stargazer to create a table
stargazer(results_matrix, type = "html",out="des3.html",digits = 4, title = "Comparative Statistics: RPA vs. Non-RPA Firms", summary = FALSE)
