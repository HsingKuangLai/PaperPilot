winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA","ABSDA1","ABCFO","ABPROD","ABEXP","RM","RM1","RM2")
X_vars <- c("ABSDA","ABSDA1","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age + RD  + ESG  + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA+ ADJROA_sq  + LGTA + Age  + RD  + ESG  + Big4 + Year")), data = data,link="logit", method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq+ LGTA + Age  + RD + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
write.csv(matched_data,trimws(cat(paste0(Y_var, "_", X_var),which=c("both")),".csv"))
}
}
}
library(sandwich)
library(lmtest)
library(MASS)
library(Matching)
library(rgenoud)
library(MatchIt)
library(dplyr)
library(knitr)
library(kableExtra)
# read CSV
data <- read.csv("Total.csv", na.strings = "#N/A")
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
######fisrt step######################### winsorizing
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA","ABSDA1","ABCFO","ABPROD","ABEXP","RM","RM1","RM2")
X_vars <- c("ABSDA","ABSDA1","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age + RD  + ESG  + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA+ ADJROA_sq  + LGTA + Age  + RD  + ESG  + Big4 + Year")), data = data,link="logit", method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq+ LGTA + Age  + RD + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
write.csv(matched_data,trimws(cat(paste0(Y_var, "_", X_var),Arg("both"),".csv"))
}
library(sandwich)
library(lmtest)
library(MASS)
library(Matching)
library(rgenoud)
library(MatchIt)
library(dplyr)
library(knitr)
library(kableExtra)
# read CSV
data <- read.csv("Total.csv", na.strings = "#N/A")
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
######fisrt step######################### winsorizing
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA","ABSDA1","ABCFO","ABPROD","ABEXP","RM","RM1","RM2")
X_vars <- c("ABSDA","ABSDA1","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age + RD  + ESG  + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA+ ADJROA_sq  + LGTA + Age  + RD  + ESG  + Big4 + Year")), data = data,link="logit", method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq+ LGTA + Age  + RD + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Output matched_data to CSV
csv_filename <- paste0("matched_data_", Y_var, "_", X_var, ".csv")
write.csv(matched_data, file = csv_filename, row.names = FALSE)
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
}
}
}
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
library(corrtable)
library(coin)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("matched_data_RM_ABSDA1.csv")
# 移除含有缺失值的觀測值
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
########### winsorizing 1%
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
# Des1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","Age","RD","ESG","MTB","OCF","LEV","LGTA")]
stargazer(mydata, type = "html", title="Descriptive statistics", digits=5, out="des1_M.html",summary.stat = c("mean","median","sd","min","max","p25","p75","n"))
#Des2
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_M.html")
#Des2.1
mydata<-data[,c("ABSDA1","ABCFO","ABPROD","ABEXP","RM")]
correlation.matrix <- correlation_matrix(mydata,type="spearman",use = "lower",show_significance = TRUE,digits = 3)
stargazer(correlation.matrix,type="html", title="Correlation Matrix",out="des2_1_M.html")
#Des3
mydata<-data[,c("RPA_Ctd","ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","Age","RD","ESG","MTB","OCF","LEV","LGTA")]
# Initialize a list to store results
variables<-c("ABSDA1","ABCFO","ABPROD","ABEXP","RM","ADJROA","Age","RD","ESG","MTB","OCF","LEV","LGTA")
results <- list()
# Loop through each variable to calculate stats and perform tests
for (var in variables) {
# Separate the groups
group_rpa <- filter(mydata, RPA_Ctd == 1) %>% pull(!!sym(var))
group_non_rpa <- filter(mydata, RPA_Ctd == 0) %>% pull(!!sym(var))
# Calculate statistics
mean_rpa <- mean(group_rpa, na.rm = TRUE)
median_rpa <- median(group_rpa, na.rm = TRUE)
sd_rpa <- sd(group_rpa, na.rm = TRUE)
mean_non_rpa <- mean(group_non_rpa, na.rm = TRUE)
median_non_rpa <- median(group_non_rpa, na.rm = TRUE)
sd_non_rpa <- sd(group_non_rpa, na.rm = TRUE)
# Wilcoxon test
test_result <- wilcox_test(reformulate('RPA_Ctd', response = var), data = mydata)
p_value <- pvalue(test_result)
# Store results
results[[var]] <- c(mean_rpa, median_rpa, sd_rpa, mean_non_rpa, median_non_rpa, sd_non_rpa, p_value)
}
# Convert results to a dataframe for easier manipulation and display
results_df <- do.call(rbind, results)
colnames(results_df) <- c("Mean RPA", "Median RPA", "SD RPA", "Mean Non-RPA", "Median Non-RPA", "SD Non-RPA", "P-Value")
rownames(results_df) <- variables
# Convert the results dataframe to a matrix for stargazer
results_matrix <- as.matrix(results_df)
# Use stargazer to create a table
stargazer(results_matrix, type = "html",out="des3_M.html",digits = 4, title = "Comparative Statistics: RPA vs. Non-RPA Firms", summary = FALSE)
library(dplyr)
library(stargazer)
library(gdata)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("clean.csv")
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Assuming 'data' is your dataframe
data$Industry <- as.factor(data$Industry)
data$Year <- as.factor(data$Year)
data<-subset(data,data$YICounts>=15)
# Initialize columns in 'data' for the abnormal measures
data$DA <- NA  # Discretionary Accruals for Jones model
data$DA1 <- NA
data$DA2 <- NA
data$ABCFO <- NA  # Abnormal Cash Flow from Operations
data$ABPROD <- NA  # Abnormal Production Costs
data$ABEXP <- NA  # Abnormal Discretionary Expenses
#Jones/MJONES/MJONES_ROA/MJONES_BMCFO
data$AC<-(data$NI_Ctd-data$OCF)/data$Asset_1
data$A1<-1/data$Asset_1
data$A21<-(data$S-data$S_1)/data$Asset_1
data$A2<-(data$S-data$S_1-(data$AR-data$AR_1))/data$Asset_1
data$A3<-data$PPE/data$Asset_1
data$A4<-data$NI_Ctd/data$Asset_1
data$A5<-data$BM
data$A6<-data$OCF/data$Asset_1
data$ROA<-data$NI_Ctd/data$Asset_1
# Assuming your dataframe is named 'data' and it has columns 'ROA', 'Industry', and 'Year'
data <- data %>%
group_by(Industry, Year) %>%
mutate(
Median_ROA = median(ROA, na.rm = TRUE), # Calculate median of ROA for each Industry-Year group
ADJROA = ROA - Median_ROA # Subtract median ROA from ROA for each row
) %>%
ungroup() # Ungroup the data frame
data$CFO<-data$OCF/data$Asset_1
data$PROD<-data$PROD/data$Asset_1
data$EXP<-data$EXP/data$Asset_1
data$R1<-1/data$Asset_1
data$R2<-data$S/data$Asset_1
data$R3<-(data$S-data$S_1)/data$Asset_1
data$R4<-(data$S_1-data$S_2)/data$Asset_1
data$R5<-data$S_1/data$Asset_1
unique_industries <- unique(data$Industry)
all_industries_data <- NULL
data <- data %>%
mutate(across(.cols = c("AC","A1", "A21","A2","A3","A4","A5","A6","ADJROA","CFO","PROD","EXP","R1","R2","R3","R4","R5"), .fns = ~winsorize(.)))
for(industry in unique_industries) {
# Subset data for the current industry
industry_data <- data %>% filter(Industry == industry)
unique_years <- unique(industry_data$Year)
for(year in unique_years) {
# Subset data for the current year within the industry
year_data <- industry_data %>% filter(Year == year)
# Perform your Jones model and Roychowdhury measures calculations here, adjusted for year_data
# Example for a simplified Jones model
jones_model <- lm(AC ~ A1 + A21 + A3, data = year_data)
year_data$DA <- residuals(jones_model)
jones_model1 <- lm(AC ~ A1 + A2 + A3, data = year_data)
year_data$DA1 <- residuals(jones_model1)
jones_model2 <- lm(AC ~ A1 + A2 + A3 + A4, data = year_data)
year_data$DA2 <- residuals(jones_model2)
# Example for Roychowdhury measures
model_cfo <- lm(CFO ~ R1 + R2 + R3, data = year_data)
year_data$ABCFO <- residuals(model_cfo)
model_prod <- lm(PROD ~ R1 + R2 + R3 + R4, data = year_data)
year_data$ABPROD <- residuals(model_prod)
model_exp <- lm(EXP ~ R1 + R5, data = year_data)
year_data$ABEXP <- residuals(model_exp)
# Append the modified data frame to the all_industries_data dataframe
if(is.null(all_industries_data)) {
all_industries_data <- year_data
} else {
all_industries_data <- rbind(all_industries_data, year_data)
}
# Save regression results to text files, adjusted to include year in the filename
file_name <- paste0("Industry_", as.character(industry), "_Year_", as.character(year), "_Regression_Results.txt")
sink(file_name)
cat("Jones Model for Year ", year, ":\n")
print(summary(jones_model))
cat("\nJones Model 1 for Year ", year, ":\n")
print(summary(jones_model1))
cat("\nJones Model 2 for Year ", year, ":\n")
print(summary(jones_model2))
cat("\nCFO Model for Year ", year, ":\n")
print(summary(model_cfo))
cat("\nPROD Model for Year ", year, ":\n")
print(summary(model_prod))
cat("\nEXP Model for Year ", year, ":\n")
print(summary(model_exp))
sink()
}
}
rawdata <- read.csv("data.csv")
# Ensure both data frames have 'Key' as a common column and it's of the same type
# It's a good practice to ensure that 'Key' columns are of the same type (e.g., character or factor)
# Merge the TAC data with rawdata based on 'Key'
Total <- merge(rawdata, all_industries_data, by = "Key")
# Write the merged data to a new CSV file
write.csv(Total, "Total.csv", row.names = FALSE)
library(sandwich)
library(lmtest)
library(MASS)
library(dplyr)
library(stargazer)
# 讀取 CSV 檔案，將 "#N/A" 轉換為真正的 NA（缺失值）
data <- read.csv("Total.csv")
# 移除含有缺失值的觀測值
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
#data<-subset(data,data$DA2<0)
########### winsorizing 1%
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$ADJROA_sq<-data$ADJROA*data$ADJROA
#Now, perform the Huber regression or any regression analysis using winsorized variables+ Year + Industry
#AM
#sink("AM_N.txt")
# Define the different values for Y and X
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
Y_vars <- c("ABSDA","ABSDA1") # Updated Y_vars to distinguish between positive and negative DA2
X_vars <- c("RM")
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
# Define the model formula
formula <- as.formula(paste0(gsub("_pos|_neg", "", Y_var), " ~ RPA_Ctd  * ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq+ LGTA + Age + RD + ESG + Big4 + Year"))
# Filter data based on the condition (if applicable)
if (Y_var == "DA1_pos") {
temp_data <- data[data$DA1 > 0, ]
} else if (Y_var == "DA1_neg") {
temp_data <- data[data$DA1 < 0, ]
} else {
temp_data <- data
}
# Fit the model with the filtered data
model <- lm(formula, data = temp_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Store the model and its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
}
}
# Output all models in a single table
stargazer(models, type = "html",
se = se_list,
title = "AM-Regression Results with Clustered Standard Errors", out = "AM_.html")
# RM
#sink("RM.txt")
# Define the different values for Y and X
# Assuming 'data' is your dataframe and 'Key' is your clustering variable
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
X_vars <- c("ABSDA","ABSDA1")
Y_vars <- c("ABCFO","ABPROD","ABEXP","RM","RM1","RM2")
for (Y_var in Y_vars) {
for (X_var in X_vars) {
# Define the model formula+ ", X_var, "
formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd  * ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq+ LGTA + Age + RD + ESG + Big4 + Year"))
# Fit the model
model <- lm(formula, data = data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Store the model and its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
}
}
# Assuming you want to output all models in a single table
stargazer(models, type = "html",
se = se_list,
title = "RM-Regression Results with Clustered Standard Errors", out = "RM_.html")
library(sandwich)
library(lmtest)
library(MASS)
library(Matching)
library(rgenoud)
library(MatchIt)
library(dplyr)
library(knitr)
library(kableExtra)
# read CSV
data <- read.csv("Total.csv", na.strings = "#N/A")
data$ABSDA<-abs(data$DA)
data$ABSDA1<-abs(data$DA1)
data$ABSDA2<-abs(data$DA2)
data$ABCFO<-data$ABCFO*(-1)
data$ABEXP<-data$ABEXP*(-1)
data$RM<-data$ABCFO+data$ABPROD+data$ABEXP
data$RM1<-data$ABCFO+data$ABEXP
data$RM2<-data$ABPROD+data$ABEXP
######fisrt step######################### winsorizing
# Define a function for winsorizing
winsorize <- function(x) {
p1 <- quantile(x, probs = 0.01)  # 1st percentile value
p99 <- quantile(x, probs = 0.99)  # 99th percentile value
x[x < p1] <- p1  # Replace values below 1st percentile
x[x > p99] <- p99  # Replace values above 99th percentile
return(x)
}
# Factorize the first 6 columns
data[1:8] <- lapply(data[1:8], factor)
# Apply the winsorize function to the remaining columns
data <- data %>%
mutate(across(.cols = 9:ncol(data), .fns = ~winsorize(.)))
data$RPA<-as.double(data$RPA)-1
data$RPA_Ctd<-as.double(data$RPA_Ctd)-1
###second step mataching
data$ADJROA_sq<-data$ADJROA*data$ADJROA
# Define your Y and X
Y_vars <- c("ABSDA","ABSDA1","ABCFO","ABPROD","ABEXP","RM","RM1","RM2")
X_vars <- c("ABSDA","ABSDA1","RM")
ps_models<-list()
models <- list() # To store lm models
se_list <- list() # To store robust SEs for each model
for (Y_var in Y_vars) {
for (X_var in X_vars) {
if (substr(Y_var,1,3)!=substr(X_var,1,3)) {
# 1. Generate propensity scores
ps_model <- glm(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq + LGTA + Age + RD  + ESG  + Big4 + Year")), data = data)
# 2. Perform nearest neighbor matching
matched_data <- matchit(as.formula(paste0("RPA_Ctd ~ ", X_var, " + LEV + OCF + MTB + ADJROA+ ADJROA_sq  + LGTA + Age  + RD  + ESG  + Big4 + Year")), data = data,link="logit", method = "nearest",distance = "glm")
matched_data <- match.data(matched_data)
# 3. Fit a linear model on the matched data
model_formula <- as.formula(paste0(Y_var, " ~ RPA_Ctd * ", X_var, " + LEV + OCF + MTB + ADJROA + ADJROA_sq+ LGTA + Age  + RD + ESG  + Big4 + Year "))
model <- lm(model_formula, data = matched_data)
# Calculate clustered standard errors
robust_se <- sqrt(diag(vcovCL(model, type = "HC0", cluster = ~Key)))
# Output matched_data to CSV
csv_filename <- paste0("matched_data_", Y_var, "_", X_var, ".csv")
write.csv(matched_data, file = csv_filename, row.names = FALSE)
# Store the model, its robust SE
models[[paste0(Y_var, "_", X_var)]] <- model
se_list[[paste0(Y_var, "_", X_var)]] <- robust_se
ps_models[[paste0(Y_var, "_", X_var)]]<-ps_model
}
}
}
# Output all models in a single table using stargazer
stargazer::stargazer(models, type = "html", out = "PSM_.html",
se = se_list, title = "PSM-Regression Results with Clustered Standard Errors")
